{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll be making a GAN to generate preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib inline\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "from loggingutils import Logger\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"last\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd.variable import Variable\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import tqdm\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the dataloader structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
       "         -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0., -1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
       "          0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0., -1.,\n",
       "          0.,  0., -1.,  0., -1.,  0.,  1.]),\n",
       " array([ 1,  4, 13,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%autoreload 2\n",
    "import importlib\n",
    "import preference_loader as pl\n",
    "data = pl.Dataset('../data_in/Practice/ED-01-03.soi')\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=20, shuffle=False)\n",
    "num_batches = len(data_loader)\n",
    "data.pairs[0], data.votes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  4 13  0  0  0  0  0  0  0  0  0  0  0]\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0., -1.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0., -1.,\n",
      "         0.,  0., -1.,  0., -1.,  0.,  1.])\n"
     ]
    }
   ],
   "source": [
    "# testing graph_visualization\n",
    "%autoreload 2\n",
    "\n",
    "import graph_visualize as gv\n",
    "i = 90\n",
    "print(data.votes[i])\n",
    "print(data.pairs[i])\n",
    "gv.vec_to_graph(data.pairs[i])\n",
    "nums_graph = gv.vote_to_graph([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x0000015108618F60>\n",
      "tensor([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  0.,\n",
      "        -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0., -1.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
      "         1.,  1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0., -1.,  0.,\n",
      "         0.,  0.,  0.,  0., -1.,  0.,  0.,  0.,  0., -1.,  0.,  0.,  0., -1.,\n",
      "         0.,  0., -1.,  0., -1.,  0.,  1.])\n"
     ]
    }
   ],
   "source": [
    "# InteractiveShell.ast_node_interactivity = \"last_expr'\"\n",
    "num_votes = len(data)\n",
    "num_features = len(data.pairs[-1])\n",
    "num_votes, num_features\n",
    "print(data_loader)\n",
    "print(data_loader.dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Originally was N -- 1024 -- 512 -- 256 -- 1\n",
    "'''\n",
    "N = num_features\n",
    "class DiscriminatorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer discriminative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        n_features = N\n",
    "        n_out = 1\n",
    "        \n",
    "        self.hidden0 = nn.Sequential( \n",
    "            nn.Linear(N, N),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(\n",
    "            nn.Linear(N, N),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(N, N),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.hidden3 = nn.Sequential(\n",
    "            nn.Linear(N, N),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            torch.nn.Linear(N, n_out),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# def matrix_to_vectors(images):\n",
    "#     return images.view(images.size(0), 784)\n",
    "\n",
    "# def vectors_to_images(vectors):\n",
    "#     return vectors.view(vectors.size(0), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "original architecture was in -- 256 -- 512 -- 1024 -- out\n",
    "         new architecture is -- in  -- in  -- in   -- out\n",
    "'''\n",
    "N = num_features\n",
    "\n",
    "class GeneratorNet(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    A three hidden-layer generative neural network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        n_features = 100\n",
    "        # hidden layer size\n",
    "        h = 512\n",
    "        n_out = N\n",
    "        \n",
    "        self.hidden0 = nn.Sequential(\n",
    "            nn.Linear(n_features, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden1 = nn.Sequential(            \n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden2 = nn.Sequential(\n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden3 = nn.Sequential(            \n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden4 = nn.Sequential(\n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden5 = nn.Sequential(            \n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden6 = nn.Sequential(\n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden7 = nn.Sequential(            \n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        self.hidden8 = nn.Sequential(\n",
    "            nn.Linear(h, h),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Linear(h, N),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hidden0(x)\n",
    "        x = self.hidden1(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = self.hidden3(x)\n",
    "        x = self.hidden4(x)\n",
    "        x = self.hidden5(x)\n",
    "        x = self.hidden6(x)\n",
    "        x = self.hidden7(x)\n",
    "        x = self.hidden8(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "# Noise\n",
    "def noise(size):\n",
    "    n = Variable(torch.randn(size, 100))\n",
    "    if torch.cuda.is_available(): return n.cuda() \n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send networks to GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiscriminatorNet(\n",
       "  (hidden0): Sequential(\n",
       "    (0): Linear(in_features=91, out_features=91, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.3)\n",
       "  )\n",
       "  (hidden1): Sequential(\n",
       "    (0): Linear(in_features=91, out_features=91, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.3)\n",
       "  )\n",
       "  (hidden2): Sequential(\n",
       "    (0): Linear(in_features=91, out_features=91, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.3)\n",
       "  )\n",
       "  (hidden3): Sequential(\n",
       "    (0): Linear(in_features=91, out_features=91, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "    (2): Dropout(p=0.3)\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=91, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GeneratorNet(\n",
       "  (hidden0): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden1): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden2): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden3): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden4): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden5): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden6): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden7): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (hidden8): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2)\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=91, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = DiscriminatorNet()\n",
    "generator = GeneratorNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU available')\n",
    "    discriminator.cuda()\n",
    "    generator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss function\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "# Number of steps to apply to the discriminator\n",
    "d_steps = 1  # In Goodfellow et. al 2014 this variable is assigned to 1\n",
    "# Number of epochs\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The author of this blog post\n",
    "https://medium.com/@utk.is.here/keep-calm-and-train-a-gan-pitfalls-and-tips-on-training-generative-adversarial-networks-edd529764aa9\n",
    "suggest using real=0 and fake=1 for improvbed 'gradient flow in the early generations'\n",
    "'''\n",
    "\n",
    "def real_data_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data\n",
    "\n",
    "def fake_data_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    if torch.cuda.is_available(): return data.cuda()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(optimizer, real_data, fake_data):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_real = loss(prediction_real, real_data_target(real_data.size(0)))\n",
    "    error_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error_fake = loss(prediction_fake, fake_data_target(real_data.size(0)))\n",
    "    error_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Return error\n",
    "    return error_real + error_fake, prediction_real, prediction_fake\n",
    "\n",
    "def train_generator(optimizer, fake_data):\n",
    "    # 2. Train Generator\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(fake_data)\n",
    "    # Calculate error and backpropagate\n",
    "    error = loss(prediction, real_data_target(prediction.size(0)))\n",
    "    error.backward()\n",
    "    # Update weights with gradients\n",
    "    optimizer.step()\n",
    "    # Return error\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Samples for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.7757, -0.6915,  1.1368,  ..., -0.5201,  0.5838, -1.3362],\n",
       "         [ 0.4720, -0.0227, -0.5619,  ...,  1.2541, -0.1693,  0.0328],\n",
       "         [ 0.4477,  0.2176,  1.0474,  ...,  0.1817, -0.5948, -0.8672],\n",
       "         ...,\n",
       "         [-0.7477, -1.8201, -0.0980,  ..., -0.6338, -0.5265, -0.8921],\n",
       "         [ 0.1012,  0.5767, -1.1666,  ...,  0.1041,  1.2442, -0.1091],\n",
       "         [-1.3373,  0.5333,  0.1832,  ..., -0.2768, -0.3609, -0.4409]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.7293, -1.2332, -2.0743,  ..., -0.6817,  0.9521, -0.5911],\n",
       "         [-0.3714, -1.9031,  1.1096,  ..., -0.2564,  0.2512, -0.4814],\n",
       "         [-1.3878,  0.9035,  0.9930,  ...,  1.1071,  0.2257, -1.2884],\n",
       "         ...,\n",
       "         [ 1.5301,  0.2816,  0.0218,  ...,  0.9370, -1.9432, -0.3013],\n",
       "         [-1.6367,  0.3584, -0.2385,  ..., -0.0284,  0.1377, -1.1257],\n",
       "         [ 0.6900, -0.4218, -1.1923,  ..., -0.6169, -0.3091,  0.4513]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.4297, -1.6490, -0.9471,  ...,  0.0022, -0.5671, -0.2851],\n",
       "         [-0.4757, -0.8639, -0.8204,  ..., -0.0804, -0.7533,  2.0023],\n",
       "         [ 0.3209,  1.1758,  1.2223,  ..., -2.0084,  1.9841, -0.8681],\n",
       "         ...,\n",
       "         [ 1.4355, -0.4767,  0.3418,  ...,  1.1851, -1.6311,  0.3464],\n",
       "         [-1.4702,  0.2818,  0.3259,  ...,  0.2254, -1.4975, -1.3456],\n",
       "         [ 0.0462, -1.1891, -0.2327,  ..., -0.4650,  1.1305,  1.3531]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.3362,  0.8986, -0.5291,  ...,  0.0693, -0.1871,  0.6123],\n",
       "         [-1.0134, -0.5199,  0.2691,  ..., -1.1315, -0.6221,  2.3147],\n",
       "         [ 0.0989, -0.4475,  0.7731,  ...,  1.3126,  1.0144,  0.4779],\n",
       "         ...,\n",
       "         [ 0.5882,  0.8036,  0.0926,  ..., -1.7222,  0.8744, -0.4107],\n",
       "         [-1.2994,  0.6756,  0.2209,  ...,  0.1382,  0.6266, -1.6441],\n",
       "         [-0.5424,  0.4910, -0.5787,  ..., -0.0431, -1.0180, -1.4178]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.7871, -0.5625,  1.8276,  ...,  1.3378,  1.1494, -0.1156],\n",
       "         [ 1.7342, -1.0265,  2.1450,  ...,  1.1482,  0.3652,  1.9996],\n",
       "         [-0.1471,  0.0476,  0.4494,  ...,  0.9310,  0.7080, -0.4090],\n",
       "         ...,\n",
       "         [-0.0913, -0.3511, -0.6030,  ..., -1.3071, -1.3278,  0.6610],\n",
       "         [-0.3665,  0.5885,  1.2235,  ..., -0.0640, -0.2950,  0.7959],\n",
       "         [-0.7406, -0.8244,  1.3340,  ..., -1.3002,  0.2735,  0.3284]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.0218, -1.5401, -0.4048,  ...,  0.5527,  0.8912, -0.9706],\n",
       "         [-0.8638,  0.3494, -0.4250,  ...,  0.1972, -0.6334, -1.3588],\n",
       "         [ 0.3324, -0.1793, -0.0309,  ...,  0.8129, -0.3674,  1.3068],\n",
       "         ...,\n",
       "         [ 0.9256,  1.0938, -0.7513,  ...,  0.2372, -0.5386, -0.1833],\n",
       "         [-1.3395,  0.0811, -0.3809,  ..., -0.0226, -0.6242,  1.5926],\n",
       "         [ 0.4403, -1.0156,  0.6834,  ..., -0.8923,  0.1863,  0.4735]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.2038, -1.0478,  1.9418,  ...,  0.3055,  0.3381,  0.8985],\n",
       "         [ 1.7940, -0.2922, -0.0985,  ...,  1.4313,  0.0664, -1.4406],\n",
       "         [-0.4055,  1.1734, -0.8892,  ...,  0.1121, -0.4279, -1.4353],\n",
       "         ...,\n",
       "         [ 0.7582, -2.5224,  0.4435,  ..., -0.2491,  0.0581,  0.6083],\n",
       "         [-1.1064,  0.8734, -0.8402,  ..., -0.6938, -0.5075,  0.1741],\n",
       "         [-0.5302,  1.9255,  1.2675,  ...,  1.6058,  0.3891,  0.3998]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.8249,  0.3988,  0.6279,  ...,  0.3578, -0.2438,  0.1012],\n",
       "         [-1.1376,  0.4633, -0.2597,  ..., -0.9159, -1.0216,  0.0363],\n",
       "         [ 1.4171, -1.1214,  0.9238,  ...,  1.1302, -2.0603,  0.8329],\n",
       "         ...,\n",
       "         [-0.3267,  1.0763, -1.8860,  ..., -0.6753,  0.6490,  0.5276],\n",
       "         [ 0.0480, -0.8344, -1.4513,  ..., -0.4799,  0.7946,  1.3478],\n",
       "         [-0.4408,  2.2576, -0.9524,  ...,  0.5639, -1.0913,  0.0248]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.1526,  0.9236,  1.1288,  ..., -0.9230,  0.9093, -0.5192],\n",
       "         [-0.0280, -0.4322,  0.3817,  ...,  0.7303, -0.6406, -2.1761],\n",
       "         [ 0.9845, -1.1984, -0.5013,  ..., -0.1099,  1.6803,  0.8502],\n",
       "         ...,\n",
       "         [-1.0737, -1.6784,  0.0220,  ...,  0.1854,  0.5499,  0.0177],\n",
       "         [ 1.4649, -0.3681,  1.6258,  ...,  0.5605, -0.9069, -2.1131],\n",
       "         [ 0.6601,  1.2077,  0.1015,  ...,  0.5659, -1.1450, -0.7020]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.1745, -2.6896,  0.1550,  ...,  1.0475, -0.5451, -0.2590],\n",
       "         [-0.5503, -0.3301,  0.0531,  ..., -0.3898, -0.6498, -0.0630],\n",
       "         [-2.0662,  0.2108, -1.2614,  ..., -2.0094, -1.4235, -0.2544],\n",
       "         ...,\n",
       "         [-0.3381,  0.7269, -0.5530,  ...,  1.1424,  0.4487,  0.0969],\n",
       "         [ 0.4595,  0.1143,  0.9267,  ..., -1.3520,  0.2623,  0.4702],\n",
       "         [ 0.1215,  0.0464, -0.1347,  ..., -1.0499, -1.7809,  0.7427]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 1.2348, -1.0526, -1.4691,  ...,  0.3455, -0.0205,  1.0999],\n",
       "         [-1.9765,  0.2849,  1.6819,  ..., -0.3908,  1.2057,  2.1048],\n",
       "         [-1.0298, -0.1202, -0.8723,  ..., -0.5904, -0.1724,  0.4660],\n",
       "         ...,\n",
       "         [ 0.9429, -1.2535, -0.0273,  ...,  1.4756,  0.5414,  0.8613],\n",
       "         [-0.9569, -0.4356, -0.1137,  ...,  0.9793,  1.9314,  2.0489],\n",
       "         [ 0.8903,  0.6670,  1.1464,  ..., -0.4151,  0.6731, -0.9579]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.3494,  0.7548,  0.3625,  ...,  0.5116,  0.5465,  0.7127],\n",
       "         [ 0.2712,  0.9080,  0.3032,  ...,  0.0459, -0.8605,  0.9791],\n",
       "         [-0.4188,  1.4145, -1.1037,  ..., -0.0210,  0.1938, -0.1925],\n",
       "         ...,\n",
       "         [ 0.0696, -2.7024, -0.6845,  ..., -0.3254,  0.7921,  0.2745],\n",
       "         [-1.7020,  0.8877, -1.4831,  ...,  0.5229, -0.3568, -0.3880],\n",
       "         [-0.9777,  1.1794, -0.4590,  ..., -0.1443,  0.5399,  0.4765]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-0.1889, -0.0715,  2.2913,  ...,  0.9286,  0.1322, -0.3053],\n",
       "         [ 0.8978, -0.3295,  0.9903,  ...,  0.3430,  1.9331, -0.5410],\n",
       "         [ 0.7355, -1.4229,  0.9639,  ..., -0.0438,  0.8633, -2.0439],\n",
       "         ...,\n",
       "         [ 0.7258, -0.2546, -0.0889,  ...,  1.2588,  1.5292,  0.6210],\n",
       "         [ 0.2976,  0.6423, -0.7909,  ...,  1.0855, -0.3343, -0.4925],\n",
       "         [-0.2672, -0.0236,  1.5570,  ..., -0.7436,  0.1624,  0.1336]],\n",
       "        device='cuda:0'),\n",
       " tensor([[-6.9537e-01, -4.1052e-01,  2.1856e-01,  ..., -2.4055e+00,\n",
       "          -2.1101e+00,  1.4355e-01],\n",
       "         [ 5.5774e-01,  1.3461e+00, -2.0116e+00,  ...,  2.3737e+00,\n",
       "           9.6079e-01,  9.0659e-01],\n",
       "         [-4.7114e-01,  1.2623e-01, -2.8817e+00,  ...,  1.7002e-01,\n",
       "          -8.2084e-01, -9.5668e-01],\n",
       "         ...,\n",
       "         [-1.0357e+00, -1.5469e+00, -7.4268e-01,  ...,  6.5714e-01,\n",
       "           1.3551e+00, -3.1284e-01],\n",
       "         [ 5.1460e-01,  5.7334e-01,  3.0857e-01,  ...,  1.1734e-01,\n",
       "           1.2284e+00, -2.9042e-01],\n",
       "         [ 9.8575e-01,  7.2091e-01,  9.8061e-01,  ..., -1.4754e-03,\n",
       "           1.7492e-01,  8.6036e-02]], device='cuda:0'),\n",
       " tensor([[-0.2538,  1.7612,  0.1483,  ..., -1.8752,  1.3030, -0.6149],\n",
       "         [ 0.9757, -0.6422,  0.0571,  ...,  0.4450, -0.6803,  0.2471],\n",
       "         [-0.5032, -1.3262,  0.4766,  ...,  0.1333, -0.8447,  0.2785],\n",
       "         ...,\n",
       "         [ 1.3363, -1.0178,  0.2881,  ..., -0.5923,  1.6766, -2.2924],\n",
       "         [ 1.4291,  0.6343, -0.0224,  ...,  1.3813,  0.5211,  0.8468],\n",
       "         [-1.5321, -1.5748,  0.2891,  ..., -1.3636, -0.1346,  2.3271]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 0.8535,  2.5387, -0.1643,  ...,  0.6016,  0.3811,  2.7776],\n",
       "         [ 0.3593, -1.6854,  1.9265,  ..., -0.8406, -0.4206, -0.0686],\n",
       "         [ 0.5280,  0.0592,  0.9334,  ..., -0.1272, -0.7595,  1.0146],\n",
       "         ...,\n",
       "         [-0.0929,  0.2513,  0.2506,  ...,  0.0640,  0.0821,  0.9154],\n",
       "         [ 0.1021, -0.6272, -0.0326,  ..., -0.4935, -0.4700,  1.1523],\n",
       "         [-1.2323,  0.9539,  0.9847,  ..., -0.1331,  0.6462,  1.1431]],\n",
       "        device='cuda:0')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test_samples = 16\n",
    "test_noise = [noise(num_test_samples) for i in range(num_test_samples)]\n",
    "# test_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [4/5], Batch Num: [3200/3205]\n",
      "Discriminator Loss: 0.0000, Generator Loss: 25.5743\n",
      "D(x): 0.0000, D(G(z)): 1.0000\n",
      "Wall time: 11min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logger = Logger(model_name='VGAN', data_name='MNIST')\n",
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print('Logging in graph_logs//{}'.format(timestr))\n",
    "g_display = None\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n_batch, real_batch in enumerate(data_loader):\n",
    "\n",
    "        # 1. Train Discriminator\n",
    "        real_data = Variable(real_batch)\n",
    "        if torch.cuda.is_available(): real_data = real_data.cuda()\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(real_data.size(0))).detach()\n",
    "        # Train D\n",
    "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\n",
    "                                                                real_data, fake_data)\n",
    "\n",
    "        # 2. Train Generator\n",
    "        # Generate fake data\n",
    "        fake_data = generator(noise(real_batch.size(0)))\n",
    "        # Train G\n",
    "        g_error = train_generator(g_optimizer, fake_data)\n",
    "\n",
    "        # Display Progress\n",
    "        if (n_batch) % 200 == 0:\n",
    "            display.clear_output(True)\n",
    "            # Display Graph\n",
    "            for i, noise_vector in enumerate(test_noise):\n",
    "                test_vote = generator(noise_vector).data.cpu()[0]\n",
    "                g_display = gv.vec_to_graph(test_vote)\n",
    "                g_display.render('../graph_logs/{}/epoch{}batch{}graph{}'.format(timestr,epoch,n_batch,i))\n",
    "            \n",
    "            # Display status Logs\n",
    "            logger.display_status(\n",
    "                epoch, num_epochs, n_batch, num_batches,\n",
    "                d_error, g_error, d_pred_real, d_pred_fake\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
